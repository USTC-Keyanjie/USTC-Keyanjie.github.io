<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>分布式lab1：Ubuntu16.04上Hadoop环境安装</title>
      <link href="/2019/03/29/Hadoop-installed-in-Ubuntu1604/"/>
      <url>/2019/03/29/Hadoop-installed-in-Ubuntu1604/</url>
      
        <content type="html"><![CDATA[<p>分布式第一次实验，怎么坑这么多！🤯</p><p>图挂了有点尴尬，明天就换七牛云的图床。</p><a id="more"></a><h2 id="Parallels虚拟机桥接模式设置"><a href="#Parallels虚拟机桥接模式设置" class="headerlink" title="Parallels虚拟机桥接模式设置"></a>Parallels虚拟机桥接模式设置</h2><p>参考这个<a href="https://blog.csdn.net/wuxiangmujingli/article/details/52671448" target="_blank" rel="noopener">文章</a>，IP的起始地址设为192.168.1.11，结束地址设为192.168.1.31</p><h2 id="hostname的配置操作"><a href="#hostname的配置操作" class="headerlink" title="hostname的配置操作"></a>hostname的配置操作</h2><ol><li><p>修改hosts文件，如下（master节点、slave1节点、slave2节点都做）：</p><pre><code class="shell">sudo su rootgedit /etc/hosts</code></pre><p>修改内容如下：</p><pre><code class="shell">192.168.1.11    master192.168.1.12    slave1192.168.1.13    slave2</code></pre></li><li><p>修改hostname，master节点上修改为master，salve1节点和slave2节点上分别修改为slave1、slave2</p><pre><code class="shell">hostname master/slave1/slave2</code></pre><p>这样不能彻底修改hostname（主机名），重启后还会还原到默认的Ubuntu，要彻底修改要修改/etc/hostname，namenode和datanode各自修改为自己的hostname</p><p>直接用编辑器打开<strong>/etc/hostname</strong>这个文件<strong>，把原来的名称</strong>删掉<strong>，</strong>不要用#注释，直接删掉，因为#没用，<strong>修改内容</strong>：(master节点上修改为master，salve1节点和slave2节点上分别修改为slave1、slave2)</p><pre><code class="shell">master/slave1/slave2</code></pre><p>退出shell客户端，重新进入，并且换成root操作</p><pre><code class="shell">exitsudo su root</code></pre></li><li><p>这些工作都做好了，互相ping一下看看能不能ping通，ping 节点名称</p><pre><code class="shell">ping master/slave1/slave2</code></pre></li></ol><h2 id="安装jdk-所有节点都做"><a href="#安装jdk-所有节点都做" class="headerlink" title="安装jdk(所有节点都做)"></a>安装jdk(所有节点都做)</h2><ol><li><p>前往<a href="http://www.oracle.com/technetwork/java/javase/downloads/index.html" target="_blank" rel="noopener">oracle Java官网</a>下载JDK</p></li><li><p>确保当前是系统账户</p><pre><code class="shell">sudo su root</code></pre></li><li><p>解压缩到指定目录（以jdk-8u201-linux-x64.tar.gz为例）</p><p>创建目录:</p><pre><code class="shell">mkdir /usr/lib/jvm</code></pre><p>解压缩到该目录:</p><pre><code class="shell">tar -zxvf jdk-8u201-linux-x64.tar.gz -C /usr/lib/jvm</code></pre></li><li><p>修改环境变量，如果提示没有装vim就使用<code>apt install vim</code>装一个:　　</p><pre><code class="shell">vim ~/.bashrc</code></pre><p>在文件末尾追加下面内容：</p><pre><code class="shell">#set oracle jdk environmentexport JAVA_HOME=/usr/lib/jvm/jdk1.8.0_201  ## 这里要注意目录要换成自己解压的jdk 目录export JRE_HOME=${JAVA_HOME}/jre  export CLASSPATH=.:${JAVA_HOME}/lib:${JRE_HOME}/lib  export PATH=${JAVA_HOME}/bin:$PATH </code></pre></li><li><p>使环境变量马上生效：</p><pre><code class="shell">source ~/.bashrc</code></pre></li><li><p>系统注册此jdk</p><pre><code class="shell">update-alternatives --install /usr/bin/java java /usr/lib/jvm/jdk1.8.0_201/bin/java 300</code></pre></li><li><p>查看java版本，看看是否安装成功：</p><pre><code class="shell">java -version</code></pre></li></ol><h2 id="SSH无密码验证配置"><a href="#SSH无密码验证配置" class="headerlink" title="SSH无密码验证配置"></a>SSH无密码验证配置</h2><h3 id="在master节点上："><a href="#在master节点上：" class="headerlink" title="在master节点上："></a>在master节点上：</h3><ol><li><p>先安装ssh</p><pre><code class="shell">sudo apt-get install ssh</code></pre></li><li><p>先创建本地公钥：</p><pre><code class="shell">mkdir ~/.sshcd ~/.ssh               rm ./id_rsa*            # 删除之前生成的公匙（如果有）ssh-keygen -t rsa       # 一直按回车就可以</code></pre></li><li><p>让 Master 节点需能无密码 SSH 本机，在 Master 节点上执行：</p><pre><code class="shell">cat ./id_rsa.pub &gt;&gt; ./authorized_keys</code></pre></li><li><p>完成后可执行 <code>ssh Master</code> 验证一下（可能需要输入 yes，成功后执行 <code>exit</code> 返回原来的终端）。接着在 master 节点将上公匙传输到 slave1 节点和slave2节点：</p><pre><code class="shell">scp ./id_rsa.pub parallels@slave1:/home/parallels/  # 向slave1节点传scp ./id_rsa.pub parallels@slave2:/home/parallels/  # 向slave2节点传</code></pre></li></ol><h3 id="在slave1节点上（slave2同理）："><a href="#在slave1节点上（slave2同理）：" class="headerlink" title="在slave1节点上（slave2同理）："></a>在slave1节点上（slave2同理）：</h3><ol><li><p>将 ssh 公匙加入授权：</p><pre><code class="shell">mkdir /root/.ssh       # 如果不存在该文件夹需先创建，若已存在则忽略cat /home/parallels/id_rsa.pub &gt;&gt; /root/.ssh/authorized_keys</code></pre></li></ol><h3 id="在master节点上测试："><a href="#在master节点上测试：" class="headerlink" title="在master节点上测试："></a>在master节点上测试：</h3><p>执行<code>ssh slave1</code>，会有这样的结果：</p><img src="http://pp41mkw5b.bkt.clouddn.com/static/images/3_1.png"><p>那么说明成功了，再执行<code>ssh slave2</code>看看。</p><h2 id="关闭防火墙"><a href="#关闭防火墙" class="headerlink" title="关闭防火墙"></a>关闭防火墙</h2><p><strong>所有节点上</strong>，执行<code>ufw disable</code>就好。</p><h2 id="安装Hadoop"><a href="#安装Hadoop" class="headerlink" title="安装Hadoop"></a>安装Hadoop</h2><h3 id="在master节点上：-1"><a href="#在master节点上：-1" class="headerlink" title="在master节点上："></a>在master节点上：</h3><p>[注]全程在root账户下运行</p><ol><li><p>到Hadoop<a href="https://hadoop.apache.org/releases.html" target="_blank" rel="noopener">官网</a>下载binary的hadoop，我下载的是<strong>hadoop-2.8.5.tar.gz</strong>文件</p></li><li><p>在/usr/local目录下建立hadoop目录</p><pre><code class="shell">sudo mkdir /usr/local/hadoop</code></pre></li><li><p>把<strong>hadoop-2.8.5.tar.gz</strong>拷贝到/usr/local/<strong>hadoop</strong>目录下，然后解压，这里的<code>&lt;path&gt;</code>写自己的下载位置</p><pre><code class="shell">cp &lt;path&gt;/hadoop-2.8.5.tar.gz /usr/local/hadoopcd /usr/local/hadooptar –zxvf hadoop-2.8.5.tar.gzcd hadoop-2.8.5</code></pre></li><li><p>在/usr/local/<strong>hadoop</strong>目录下新建tmp文件夹和hdfs文件夹</p><pre><code class="shell">sudo mkdir tmpsudo mkdir hdfs</code></pre></li><li><p>编辑hadoop-2.8.5/etc/hadoop/<strong>hadoop-env.sh</strong>文件，把JAVA_HOME设置成Java安装根路径，如下：</p><pre><code class="shell">export JAVA_HOME=/usr/lib/jvm/jdk1.8.0_201</code></pre></li><li><p>新建<strong>slaves</strong>文件</p><pre><code class="shell">sudo vi slaves</code></pre><p>添加这两条</p><pre><code>slave1slave2</code></pre></li><li><p>编辑<strong>master</strong>文件，全文改为<code>master</code></p></li><li><p>修改hadoop-2.8.5/etc/hadoop/<strong>core-site.xml</strong>文件</p><pre><code class="xml">&lt;configuration&gt;    &lt;property&gt;        &lt;name&gt;fs.defaultFS&lt;/name&gt;        &lt;value&gt;hdfs://master:9000&lt;/value&gt;    &lt;/property&gt;    &lt;property&gt;        &lt;name&gt;hadoop.tmp.dir&lt;/name&gt;        &lt;value&gt;file:/usr/local/hadoop/tmp&lt;/value&gt;        &lt;description&gt;Abase for other temporary directories.&lt;/description&gt;    &lt;/property&gt;&lt;/configuration&gt;</code></pre></li><li><p>修改hadoop-2.8.5/etc/hadoop/<strong>hdfs-site.xml</strong>文件</p><pre><code class="xml">&lt;configuration&gt;    &lt;property&gt;        &lt;name&gt;dfs.namenode.secondary.http-address&lt;/name&gt;        &lt;value&gt;master:50090&lt;/value&gt;    &lt;/property&gt;    &lt;property&gt;        &lt;name&gt;dfs.replication&lt;/name&gt;        &lt;value&gt;3&lt;/value&gt;    &lt;/property&gt;    &lt;property&gt;        &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt;        &lt;value&gt;file:/usr/local/hadoop/hdfs/name&lt;/value&gt;    &lt;/property&gt;    &lt;property&gt;        &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt;        &lt;value&gt;file:/usr/local/hadoop/hdfs/data&lt;/value&gt;    &lt;/property&gt;&lt;/configuration&gt;</code></pre></li><li><p>修改hadoop-2.8.5/etc/hadoop/<strong>mapred-site.xml</strong>文件(可能需要先重命名，默认文件名为 mapred-site.xml.template)</p><pre><code class="xml">&lt;configuration&gt;   &lt;property&gt;       &lt;name&gt;mapreduce.framework.name&lt;/name&gt;       &lt;value&gt;yarn&lt;/value&gt;   &lt;/property&gt;   &lt;property&gt;       &lt;name&gt;mapreduce.jobhistory.address&lt;/name&gt;       &lt;value&gt;master:10020&lt;/value&gt;   &lt;/property&gt;   &lt;property&gt;       &lt;name&gt;mapreduce.jobhistory.webapp.address&lt;/name&gt;       &lt;value&gt;master:19888&lt;/value&gt;   &lt;/property&gt;&lt;/configuration&gt;</code></pre></li><li><p>修改hadoop-2.8.5/etc/hadoop/<strong>yarn-site.xml</strong>文件</p><pre><code class="xml">&lt;configuration&gt;    &lt;property&gt;        &lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt;        &lt;value&gt;master&lt;/value&gt;    &lt;/property&gt;    &lt;property&gt;        &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;        &lt;value&gt;mapreduce_shuffle&lt;/value&gt;    &lt;/property&gt;&lt;/configuration&gt;</code></pre></li><li><p>将配置好的文件复制到<strong>各个slave</strong>节点上：</p><pre><code class="shell">cd /usr/localsudo rm -r ./hadoop/tmp     # 删除 Hadoop 临时文件tar -zcf ~/hadoop.master.tar.gz ./hadoop   # 先压缩再复制cd ~scp ./hadoop.master.tar.gz slave1:/home/parallelsscp ./hadoop.master.tar.gz slave2:/home/parallels</code></pre></li></ol><h3 id="在slave1节点上："><a href="#在slave1节点上：" class="headerlink" title="在slave1节点上："></a>在slave1节点上：</h3><ol><li><p>解压文件，并修改<strong>owner</strong></p><pre><code class="shell">sudo rm -r /usr/local/hadoop    # 删掉旧的（如果存在）sudo tar -zxf /home/parallels/hadoop.master.tar.gz -C /usr/localsudo chown -R parallels /usr/local/hadoop</code></pre></li></ol><h3 id="回到master节点"><a href="#回到master节点" class="headerlink" title="回到master节点"></a>回到master节点</h3><ol><li><p>到/<strong>etc</strong>目录下找到<strong>profile</strong>文件，添加以下语句：</p><pre><code class="shell">export HADOOP_HOME=/usr/local/hadoop/hadoop-2.8.5/binexport PATH=$PATH:$HADOOP_HOME:$PATH</code></pre></li><li><p>再执行一条语句，将文件进行重载</p><pre><code class="shell">source /etc/profile</code></pre></li><li><p>到/usr/local/hadoop/hadoop-2.8.5/<strong>bin</strong>文件夹下，在 Master 节点执行 NameNode 的格式化</p><pre><code class="shell">cd /usr/local/hadoop/hadoop-2.8.5/binhadoop namenode -format</code></pre></li><li><p>接着可以启动 hadoop 了，启动需要在 <strong>Master</strong> 节点的<strong>sbin</strong>文件夹中进行：</p><pre><code class="shell">cd /usr/local/hadoop/hadoop-2.8.5/sbin./start-all.shmr-jobhistory-daemon.sh start historyserver</code></pre><img src="http://pp41mkw5b.bkt.clouddn.com/static/images/3_5.png"><p>通过命令 <code>jps</code> 可以查看各个节点所启动的进程。正确的话，在 Master 节点上可以看到 NameNode、ResourceManager、SecondrryNameNode、JobHistoryServer 进程。</p><img src="http://pp41mkw5b.bkt.clouddn.com/static/images/3_2.png"></li><li><p>分别进入slave1节点和slave2节点，使用<code>jps</code>命令查看运行情况</p><img src="http://pp41mkw5b.bkt.clouddn.com/static/images/3_6.png"><img src="http://pp41mkw5b.bkt.clouddn.com/static/images/3_8.png"></li><li><p>在namenode上查看集群状态</p><pre><code class="shell">hadoop dfsadmin -report</code></pre><p>此时可以通过在浏览器中打开<a href="http://master:50070" target="_blank" rel="noopener">http://master:50070</a>查看。</p><img src="http://pp41mkw5b.bkt.clouddn.com/static/images/3_3.png"></li></ol>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>删数问题的贪心选择策略证明</title>
      <link href="/2019/03/28/2%E5%88%A0%E6%95%B0%E9%97%AE%E9%A2%98%E7%9A%84%E8%B4%AA%E5%BF%83%E9%80%89%E6%8B%A9%E7%AD%96%E7%95%A5%E8%AF%81%E6%98%8E/"/>
      <url>/2019/03/28/2%E5%88%A0%E6%95%B0%E9%97%AE%E9%A2%98%E7%9A%84%E8%B4%AA%E5%BF%83%E9%80%89%E6%8B%A9%E7%AD%96%E7%95%A5%E8%AF%81%E6%98%8E/</url>
      
        <content type="html"><![CDATA[<blockquote><p><strong>题目：在一个n位的正整数A[1…n]中删除其中任意k(k≤n)个数字后，剩下的数字按原次序组成一个新的正整数。对于给定的n位正整数A和k，设计一个贪心算法，使得剩下的数字组成的新数最小。</strong><br><strong>如：A=278693，k=4时最小新数为23，k=3时为263</strong></p></blockquote><a id="more"></a><p>刚刚证明出来贪心选择性质，先写下，之后再慢慢补充全部思路。</p><h2 id="贪心选择策略"><a href="#贪心选择策略" class="headerlink" title="贪心选择策略"></a><strong>贪心选择策略</strong></h2><p>从高位向低位进行搜索：</p><ol><li>如果A[1…n]是一条递增序列，那么就删除最后一个数；</li><li>如果A[1…n]含有严格递减子序列，那么就删除第一个严格递减子序列的首字符。</li></ol><h2 id="贪心选择性质证明"><a href="#贪心选择性质证明" class="headerlink" title="贪心选择性质证明"></a>贪心选择性质证明</h2><p>假设A中有n个元素，将A中的每个元素进行编号为$a_x(1\leq x\leq n)​$：<br>$$<br>A=[a_1,a_2,…,a_{n-1},a_n]<br>$$</p><ol><li>如果A[1…n]是一条递增序列，那么就删除最后一个数；</li></ol><p>记原本A所代表的数值为$T_A​$，则有：<br>$$<br>T_A=a_1 \times 10^{n-1}+a_2\times10^{n-2}+…+a_{n-1}\times10+a_n<br>$$</p><p>记删除最后一个数后，A变为A’，A’所代表的数值为$T_{A’}$，则有：</p><p>$$<br>T_{A’}=a_1\times10^{n-2}+a_2 \times 10^{n-3}+…+a_{n-2} \times 10+a_{n-1}<br>$$</p><p>如果不删除最后一个数，而是删除另一个数$a_q(1\leq q&lt; n)$，此时A变为A’’，A’’所代表的数值为$T_{A’’}$，则有： </p><p>$$<br>T_{A’’}=a_1 \times 10^{n-2}+a_2 \times 10^{n-3}+…+a_{q-1} \times 10^{n-q}+a_{q+1} \times 10^{n-q-1}+…+a_{n-1} \times 10+a_n<br>$$</p><p>用作差法来比较$T_{A’}$和$T_{A’’}$的大小：</p><p>$$<br>T_{A’}-T_{A’’}=(a_q-a_{q+1}) \times 10^{n-q-1}+(a_{q+1}-a_{q+2}) \times 10^{n-q-2}+…+(a_{n-2}-a_{n-1}) \times 10+(a_{n-1}-a_{n})<br>$$</p><p>由于A是一条递增序列，所以有：</p><p>$$<br>a_{q}\leq a_{q+1},a_{q+1}\leq a_{q+2},…,a_{n-2}\leq a_{n-1},a_{n-1}\leq a_{n}<br>$$</p><p>即：</p><p>$$<br>a_{q}-a_{q+1}\leq 0,a_{q+1}-a_{q+2}\leq 0,…,a_{n-2}-a_{n-1}\leq 0,a_{n-1}-a_{n}\leq 0<br>$$</p><p>所以有$T_{A’}-T_{A’’}\leq 0$，那么$T_{A’}$是A删完一个数后，所组成的最小数值。贪心选择是安全的。</p><ol start="2"><li>如果A[1…n]含有严格递减子序列，那么就删除第一个严格递减子序列的首字符。</li></ol><p>(1) 先考虑一种情况，A中只有两段单调子区间，且高位部分是递增子区间，低位部分是递减子区间。那么A中的数就是先上升再下降，像一座山一样。如果删除第一个递减子序列的首字符是安全的，也就是删除山顶的数是安全的。</p><p>假设在A中，有3个连在一起的数$a_i,a_j,a_k(1\leq i&lt; j&lt; k\leq n)$，其中$(a_1,a_j)$是递增序列，$(a_j,a_n)$是递减序列。</p><p>记原本A所代表的数值为$T_A$，则有：</p><p>$$<br>T_A=a_1 \times 10^{n-1}+a_2 \times 10^{n-2}+…+a_i \times 10^{n-i}+a_j \times 10^{n-j}+a_k \times 10^{n-k}+…+a_{n-1} \times 10+a_n<br>$$</p><p>删除$a_j$后，A变为A’，A’所代表的数值为$T_{A’}$，则有：</p><p>$$<br>T_{A’}=a_1 \times 10^{n-2}+a_2 \times 10^{n-3}+…+a_i \times 10^{n-i-1}+a_k \times 10^{n-k}+…+a_{n-1} \times 10+a_{n}<br>$$</p><p>如果不删除$a_j$，而是删除另一个数$a_q$。</p><p>a) 当$1\leq q&lt; j$时，此时A变为A’’，A’’所代表的数值为$T_{A’’}$，则有：<br>$$<br>T_{A’’}=a_1 \times 10^{n-2}+a_2 \times 10^{n-3}+…+a_{q-1} \times 10^{n-q}+a_{q+1} \times 10^{n-q-1}+…+a_j \times 10^{n-j}+…+a_{n-1} \times 10+a_{n}<br>$$</p><p>用作差法来比较$T_{A’}$和$T_{A’’}$的大小：</p><p>$$<br>T_{A’}-T_{A’’}=(a_q-a_{q+1}) \times 10^{n-q-1}+(a_{q+1}-a_{q+2}) \times 10^{n-q-2}+…+(a_{i}-a_{j}) \times 10^{n-j}<br>$$</p><p>由于$(a_1,a_j)$是一条递增序列，所以有：</p><p>$$<br>a_{q}\leq a_{q+1},a_{q+1}\leq a_{q+2},…,a_{i}\leq a_{j}<br>$$</p><p>即：</p><p>$$<br>a_{q}-a_{q+1}\leq 0,a_{q+1}-a_{q+2}\leq 0,…,a_{i}-a_{j}\leq 0<br>$$</p><p>所以有$T_{A’}-T_{A’’}\leq 0$，那么$T_{A’}$是A删完$a_q(1\leq q &lt; j)$后，所组成的最小数值。贪心选择是安全的。</p><p>(b) 当$j &lt; q\leq n$时，此时A变为A’’’，A’’’所代表的数值为$T_{A’’’}$，则有： </p><p>$$<br>T_{A’’’}=a_1 \times 10^{n-2}+a_2 \times 10^{n-3}+…+a_j \times 10^{n-j-1}+…+a_{q-1} \times 10^{n-q}+a_{q+1} \times 10^{n-q-1}…+a_{n-1} \times 10+a_{n}<br>$$</p><p>用作差法来比较$T_{A’}$和$T_{A’’’}$的大小：</p><p>$$<br>T_{A’}-T_{A’’}=(a_k-a_j) \times 10^{n-k}+…+(a_{q-1}-a_{q-2}) \times 10^{n-q+1}+(a_{q}-a_{q-1}) \times 10^{n-q}<br>$$</p><p>由于$(a_j,a_{n})$是一条递减序列，所以有：</p><p>$$<br>a_{k}\leq a_{j},a_{q-1}\leq a_{q-2},…,a_{q}\leq a_{q-1}<br>$$</p><p>即：</p><p>$$<br>a_{k}-a_{j}\leq 0,a_{q-1}-a_{q-2}\leq 0,a_{q}-a_{q-1}\leq 0<br>$$</p><p>所以有$T_{A’}-T_{A’’’}\leq 0$，那么$T_{A’}$是A删完$a_q(j&lt; q \leq n)$后，所组成的最小数值。贪心选择是安全的。<br>综上(a)(b)所述，若A中只有两段单调子区间，且高位部分是递增子区间，低位部分是递减子区间，那么删去此递减子区间的首字符后，所组成的数是最小数值。贪心选择是安全的。</p><p>(2) 现在已经证明了如果A中只有一个山，那么删除山顶元素是最合适的。如果A中有多个山峰该如何处理？</p><p>换句话说，如果A中不止有2段单调子区间，而是由很多不同的单调子区间所组成，那应该如何处理？</p><p>这个问题看上去有点复杂了，我画个图吧：</p><img src="http://pp41mkw5b.bkt.clouddn.com/static/images/2_1.jpg"><p>其实把图画出来后，我尝试着删除第一个山的山顶元素，删完后发现，现在的$a_6=a_5$，而$a_7=a_7$：</p><img src="http://pp41mkw5b.bkt.clouddn.com/static/images/2_2.jpg"><p>但如果删除第一个山之后的任意一个元素的话，删完后发现$a_6=a_5$，而现在的$a_7=a_6$。</p><img src="http://pp41mkw5b.bkt.clouddn.com/static/images/2_3.jpg"><p>由于$a_6&gt;a_7​$，所以不管后面删哪个元素，都会比删除$a_6​$所得到的数要大。</p><p>数学证明如下：</p><p>假设在A中，有3个连在一起的数$a_i,a_j,a_k(1\leq i&lt; j&lt; k\leq n)​$，还有另一个数$a_r(k \leq r &lt; n)​$，，其中$(a_1,a_j)​$是递增序列，$(a_j,a_r)​$是递减序列。</p><p>记原本A所代表的数值为$T_A$，则有：</p><p>$$<br>T_A=a_1 \times 10^{n-1}+a_2 \times 10^{n-2}+…+a_i \times 10^{n-i}+a_j \times 10^{n-j}+a_k \times 10^{n-k}+…+a_{n-1} \times 10+a_n<br>$$</p><p>删除$a_j​$后，A变为A’，A’所代表的数值为$T_{A’}​$，则有：</p><p>$$<br>T_{A’}=a_1 \times 10^{n-2}+a_2 \times 10^{n-3}+…+a_i \times 10^{n-i-1}+a_k \times 10^{n-k}+…<br>$$</p><p>如果不删除$a_j$，而是删除另一个数$a_q(r \leq q \leq n)$。此时A变为A’’，A’’所代表的数值为$T_{A’’}$，则有： </p><p>$$<br>T_{A’’}=a_1 \times 10^{n-2}+a_2 \times 10^{n-3}+…+a_i \times 10^{n-i-1}+a_j \times 10^{n-j-1}+…<br>$$</p><p>发现$T_{A’}$中的$10^{n-k}$的系数是$a_k$，而$T_{A’’}$中的$10^{n-k}$的系数是$a_j$，由于$a_k&lt; a_j$，那么必有$T_{A’}&lt; T_{A’’}$，所以删除第一个山峰的峰值是安全的。也就是如果A[1…n]含有严格递减子序列，那么就删除第一个严格递减子序列的首字符。贪心选择是安全的。</p><p>综上，贪心选择性质成立。</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>LeetCode 17. Letter Combinations of a Phone Number</title>
      <link href="/2019/03/27/LeetCode%2017.%20Letter%20Combinations%20of%20a%20Phone%20Number/"/>
      <url>/2019/03/27/LeetCode%2017.%20Letter%20Combinations%20of%20a%20Phone%20Number/</url>
      
        <content type="html"><![CDATA[<p>LeetCode 17题解</p><a id="more"></a><h2 id="题目"><a href="#题目" class="headerlink" title="题目"></a>题目</h2><p>Given a string containing digits from <code>2-9</code> inclusive, return all possible letter combinations that the number could represent.</p><p>A mapping of digit to letters (just like on the telephone buttons) is given below. Note that 1 does not map to any letters.</p><p><img src="http://upload.wikimedia.org/wikipedia/commons/thumb/7/73/Telephone-keypad2.svg/200px-Telephone-keypad2.svg.png" alt="img"></p><p><strong>Example:</strong></p><pre><code>Input: &quot;23&quot;Output: [&quot;ad&quot;, &quot;ae&quot;, &quot;af&quot;, &quot;bd&quot;, &quot;be&quot;, &quot;bf&quot;, &quot;cd&quot;, &quot;ce&quot;, &quot;cf&quot;].</code></pre><p><strong>Note:</strong></p><p>Although the above answer is in lexicographical order, your answer could be in any order you want.</p><h2 id="题目大意："><a href="#题目大意：" class="headerlink" title="题目大意："></a><strong>题目大意：</strong></h2><p>以一定顺序按下手机上的2~9数字，输出所有的字符组合。</p><p>##分析：<br>每个数字都代表了3-4个字母，依照顺序按下数字后所产生的字符串，就是一个树的搜索问题，可使用dfs搜索此树。</p><pre><code class="c++">class Solution {public:    vector&lt;string&gt; result;    vector&lt;string&gt; table = {&quot;abc&quot;, &quot;def&quot;, &quot;ghi&quot;, &quot;jkl&quot;, &quot;mno&quot;, &quot;pqrs&quot;, &quot;tuv&quot;, &quot;wxyz&quot;};    vector&lt;string&gt; letterCombinations(string digits) {        if (digits == &quot;&quot;)            return result;        dfs(digits, &quot;&quot;);        return result;    }    void dfs(string digits, string recur) {        if (digits == &quot;&quot;) {            result.push_back(recur);        } else {            int num = digits[0] - &#39;2&#39;;            for (char c : table[num]) {                f(digits.substr(1), recur + c);            }        }    }};</code></pre>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>LeetCode 16. 3Sum Closest</title>
      <link href="/2019/03/27/LeetCode%2016.%203Sum%20Closest/"/>
      <url>/2019/03/27/LeetCode%2016.%203Sum%20Closest/</url>
      
        <content type="html"><![CDATA[<p>Given an array <code>nums</code> of <em>n</em> integers and an integer <code>target</code>, find three integers in <code>nums</code> such that the sum is closest to <code>target</code>. Return the sum of the three integers. You may assume that each input would have exactly one solution.</p><p><strong>Example:</strong></p><pre><code>Given array nums = [-1, 2, 1, -4], and target = 1.The sum that is closest to the target is 2. (-1 + 2 + 1 = 2).</code></pre><p><strong>思路：和15题差不多，先排序，然后定好三个数中一个数，再搜索剩下两个数。</strong></p><pre><code class="c++">class Solution {public:    int threeSumClosest(vector&lt;int&gt;&amp; nums, int target) {        int closed_sum = 0;        int min_dis = INT_MAX;        sort(nums.begin(), nums.end());        for (int i = 0; i &lt; nums.size() - 2; i++) {            if (i == 0 || (i &gt; 0 &amp;&amp; nums[i] != nums[i - 1])) {                int l = i + 1, r = nums.size() - 1, sum = target - nums[i];                while (l &lt; r) {                    if (nums[l] + nums[r] == sum) {                        return target;                    } else if (nums[l] + nums[r] &lt; sum) {                        if (-(nums[l] + nums[r] - sum) &lt; min_dis) {                            min_dis = -(nums[l] + nums[r] - sum);                            closed_sum = nums[l] + nums[r] + nums[i];                        }                        do {                            l++;                        } while (l &lt; r &amp;&amp; nums[l] == nums[l-1]);                    } else {                        if (nums[l] + nums[r] - sum &lt; min_dis) {                            min_dis = nums[l] + nums[r] - sum;                            closed_sum = nums[l] + nums[r] + nums[i];                        }                        do {                            r--;                        }while (l &lt; r &amp;&amp; nums[r] == nums[r+1]);                    }                }            }        }        return closed_sum;    }};</code></pre>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>LeetCode 15. 3Sum</title>
      <link href="/2019/03/27/LeetCode%2015.%203Sum/"/>
      <url>/2019/03/27/LeetCode%2015.%203Sum/</url>
      
        <content type="html"><![CDATA[<p>Given an array <code>nums</code> of <em>n</em> integers, are there elements <em>a</em>, <em>b</em>, <em>c</em> in <code>nums</code> such that <em>a</em> + <em>b</em> + <em>c</em> = 0? Find all unique triplets in the array which gives the sum of zero.</p><p><strong>Note:</strong></p><p>The solution set must not contain duplicate triplets.</p><p><strong>Example:</strong></p><pre><code>Given array nums = [-1, 0, 1, 2, -1, -4],A solution set is:[  [-1, 0, 1],  [-1, -1, 2]]</code></pre><p><strong>思路：目标是搜索一个三元组，先把所有的数排序，然后定好一个数，再搜索剩下的两个数。</strong><br><strong>两个指针分别从左右开始搜索：</strong><br><strong>1、若三个数之和为0，则搜索到，同时向中间移动；</strong><br><strong>2、若三个数之和小于0，则把左边的指针向右移动，使得和增加；</strong><br><strong>3、若三个数之和大于0，则把右边的指针向左移动，使得和减小；</strong></p><pre><code class="c++">class Solution {public:    vector&lt;vector&lt;int&gt;&gt; threeSum(vector&lt;int&gt;&amp; nums) {        vector&lt;vector&lt;int&gt;&gt; result;        if (nums.size() &lt; 3) {            return result;        }        sort(nums.begin(), nums.end());        for (int i = 0; i &lt; nums.size() - 2; i++) {            if (i == 0 || (i &gt; 0 &amp;&amp; nums[i] != nums[i - 1])) {                int l = i + 1, r = nums.size() - 1, sum = -nums[i];                while (l &lt; r) {                    if (nums[l] + nums[r] == sum) {                        vector&lt;int&gt; tmp = {nums[i], nums[l], nums[r]};                        result.push_back(tmp);                        do {                            l++;                        } while (l &lt; r &amp;&amp; nums[l] == nums[l-1]);                        do {                            r--;                        } while (l &lt; r &amp;&amp; nums[r] == nums[r+1]);                    } else if (nums[l] + nums[r] &lt; sum) {                        do {                            l++;                        }while (l &lt; r &amp;&amp; nums[l] == nums[l-1]);                    } else {                        do {                            r--;                        }while (l &lt; r &amp;&amp; nums[r] == nums[r+1]);                    }                }            }        }        return result;    }};</code></pre>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>LeetCode 14. Longest Common Prefix</title>
      <link href="/2019/03/27/LeetCode%2014.%20Longest%20Common%20Prefix/"/>
      <url>/2019/03/27/LeetCode%2014.%20Longest%20Common%20Prefix/</url>
      
        <content type="html"><![CDATA[<p>Write a function to find the longest common prefix string amongst an array of strings.</p><p>If there is no common prefix, return an empty string <code>&quot;&quot;</code>.</p><p><strong>Example 1:</strong></p><pre><code>Input: [&quot;flower&quot;,&quot;flow&quot;,&quot;flight&quot;]Output: &quot;fl&quot;</code></pre><p><strong>Example 2:</strong></p><pre><code>Input: [&quot;dog&quot;,&quot;racecar&quot;,&quot;car&quot;]Output: &quot;&quot;Explanation: There is no common prefix among the input strings.</code></pre><p><strong>Note:</strong></p><p>All given inputs are in lowercase letters <code>a-z</code>.</p><pre><code class="c++">class Solution {public:    string longestCommonPrefix(vector&lt;string&gt;&amp; strs) {        if (strs.size() == 0) {            return &quot;&quot;;        }        vector&lt;char*&gt; points;        for (int i = 0; i &lt; strs.size(); i++) {            points.push_back(&amp;strs[i][0]);        }        string result = &quot;&quot;;        char cur = &#39;\0&#39;;        while (true) {            if (*points[0] == &#39;\0&#39;)                return result;            else {                cur = *points[0];                points[0]++;            }            for (int i = 1; i &lt; points.size(); i++) {                if (*points[i] != cur) {                    return result;                } else {                    points[i]++;                }            }            result += cur;        }        return result;    }};</code></pre>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>LeetCode 13. Roman to Integer</title>
      <link href="/2019/03/27/LeetCode%2013.%20Roman%20to%20Integer/"/>
      <url>/2019/03/27/LeetCode%2013.%20Roman%20to%20Integer/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><p>Roman numerals are represented by seven different symbols: <code>I</code>, <code>V</code>, <code>X</code>, <code>L</code>, <code>C</code>, <code>D</code> and <code>M</code>.</p><pre><code>Symbol       ValueI             1V             5X             10L             50C             100D             500M             1000</code></pre><p>For example, two is written as <code>II</code> in Roman numeral, just two one’s added together. Twelve is written as, <code>XII</code>, which is simply <code>X</code> + <code>II</code>. The number twenty seven is written as <code>XXVII</code>, which is <code>XX</code> + <code>V</code> + <code>II</code>.</p><p>Roman numerals are usually written largest to smallest from left to right. However, the numeral for four is not <code>IIII</code>. Instead, the number four is written as <code>IV</code>. Because the one is before the five we subtract it making four. The same principle applies to the number nine, which is written as <code>IX</code>. There are six instances where subtraction is used:</p><ul><li><code>I</code> can be placed before <code>V</code> (5) and <code>X</code> (10) to make 4 and 9.</li><li><code>X</code> can be placed before <code>L</code> (50) and <code>C</code> (100) to make 40 and 90.</li><li><code>C</code> can be placed before <code>D</code> (500) and <code>M</code> (1000) to make 400 and 900.</li></ul><p>Given a roman numeral, convert it to an integer. Input is guaranteed to be within the range from 1 to 3999.</p><pre><code class="c++">class Solution {public:    int romanToInt(string s) {        int num = 0;        for(int i = 0; i &lt; s.length(); i++) {            switch(s[i]) {                case &#39;M&#39;:                      num += 1000;                    break;                case &#39;D&#39;:                    num += 500;                    break;                case &#39;L&#39;:                    num += 50;                    break;                case &#39;V&#39;:                    num += 5;                    break;                case &#39;C&#39;:                    if (s[i+1] == &#39;M&#39;) {                        num += 900;                        i++;                    } else if (s[i+1] == &#39;D&#39;){                        num += 400;                        i++;                    } else {                        num += 100;                    }                    break;                case &#39;X&#39;:                    if (s[i+1] == &#39;C&#39;) {                        num += 90;                        i++;                    } else if (s[i+1] == &#39;L&#39;){                        num += 40;                        i++;                    } else {                        num += 10;                    }                    break;                case &#39;I&#39;:                    if (s[i+1] == &#39;X&#39;) {                        num += 9;                        i++;                    } else if (s[i+1] == &#39;V&#39;){                        num += 4;                        i++;                    } else {                        num += 1;                    }                    break;                default:                    break;            }        }        return num;    }};</code></pre>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>高图实验1 图像灰度变换</title>
      <link href="/2019/03/27/%E9%AB%98%E5%9B%BE%E5%AE%9E%E9%AA%8C1%20%E5%9B%BE%E5%83%8F%E7%81%B0%E5%BA%A6%E5%8F%98%E6%8D%A2/"/>
      <url>/2019/03/27/%E9%AB%98%E5%9B%BE%E5%AE%9E%E9%AA%8C1%20%E5%9B%BE%E5%83%8F%E7%81%B0%E5%BA%A6%E5%8F%98%E6%8D%A2/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><h2 id="实验内容"><a href="#实验内容" class="headerlink" title="实验内容:"></a>实验内容:</h2><p><strong>1、利用 OpenCV 读取图像</strong><br><strong>具体内容:用打开 OpenCV 打开图像，并在窗口中显示</strong></p><p><strong>2、灰度图像二值化处理</strong><br><strong>具体内容:设置并调整阈值对图像进行二值化处理。</strong></p><p><strong>3、灰度图像的对数变换</strong><br><strong>具体内容:设置并调整 r 值对图像进行对数变换。</strong></p><p><strong>4、灰度图像的伽马变换</strong><br><strong>具体内容:设置并调整γ值对图像进行伽马变换。</strong></p><p><strong>5、彩色图像的补色变换</strong><br><strong>具体内容:对彩色图像进行补色变换。</strong></p><p><strong>第一次实验比较简单，所有讲解就用注释标注在代码中啦~</strong></p><pre><code class="c++">#include &lt;iostream&gt;#include &lt;opencv2/opencv.hpp&gt;#include &lt;opencv2/highgui/highgui.hpp&gt;#include &lt;opencv2/core/core.hpp&gt;#include &lt;opencv2/imgcodecs/imgcodecs.hpp&gt;using namespace std;using namespace cv;void showImg(Mat&amp;, string);void Threshold(Mat&amp;, double);void logTransform(Mat&amp;, int);void gammaTransform(Mat&amp;, int, double);void ComplementaryColorTransform(Mat&amp;);int main(int argc, char** argv) {    // 以黑白方式载入图像    Mat img = imread(&quot;/Users/alan.ke/Pictures/image.jpg&quot;, 0);    // 检测图像是否真的被载入    if(img.empty())        return -1;    showImg(img, &quot;original&quot;);    Threshold(img, 30);    logTransform(img, 1);    gammaTransform(img, 1, 0.5);    // 返回一个3通道的彩色图像    img = imread(&quot;/Users/alan.ke/Pictures/image.jpg&quot;, 1);    ComplementaryColorTransform(img);    return 0;}// 显示一张图片void showImg(Mat &amp;srcImg, string title) {    // 新建一个标题为&quot;Example1&quot;的窗口，WINDOW_AUTOSIZE表示窗口的大小会根据载入图像的大小进行调整    namedWindow(title, WINDOW_AUTOSIZE);    // 将所选图片绘制到窗口上，且显示    imshow(title, srcImg);    // 无限等待直到用户按下某个键    waitKey(0);    // 销毁窗口    destroyWindow(title);}// 灰度图像二值化处理void Threshold(Mat &amp;srcImg, double thresh) {    Mat resultImg;    resultImg = srcImg.clone();    // InputArray src,  源图像    // OutputArray dst, 输出图像    // double thresh,   门限值    // double maxval,   最大值    // int type,        函数类型选择，THRESH_BINARY，THRESH_BINARY_INV，THRESH_TRUNC，THRESH_TOZERO，THRESH_TOZERO_INV    threshold(srcImg, resultImg, thresh, 200.0, THRESH_BINARY);    showImg(resultImg, &quot;Threshold&quot;);}// 灰度图像的对数变换void logTransform(Mat &amp;srcImg, int c) {    Mat resultImg = srcImg.clone();    // OpenCV有为Mat提供了与STL相兼容的迭代器    Mat_&lt;uchar&gt;::iterator it = resultImg.begin&lt;uchar&gt;();    Mat_&lt;uchar&gt;::iterator itend = resultImg.end&lt;uchar&gt;();    for(; it!=itend; it++){        // 依据log变换公式: c * log(1 + data)        (*it) = c * log(1 + (*it));    }    // 归一化处理    normalize(resultImg, resultImg, 0, 255, cv::NORM_MINMAX);    showImg(resultImg, &quot;logTransform&quot;);}// 灰度图像的伽马变换void gammaTransform(Mat &amp;srcImg, int c, double gamma) {    Mat resultImg = srcImg.clone();    Mat_&lt;uchar&gt;::iterator it = resultImg.begin&lt;uchar&gt;();    Mat_&lt;uchar&gt;::iterator itend = resultImg.end&lt;uchar&gt;();    for(; it!=itend; it++) {        // 依据gamma变换公式: c * pow(data, gamma)        (*it) = c * pow((*it), gamma);    }    // 归一化处理    normalize(resultImg, resultImg, 0, 255, cv::NORM_MINMAX);    showImg(resultImg, &quot;gammaTransform&quot;);}// 彩色图像的补色变换void ComplementaryColorTransform(Mat &amp;srcImg) {    Mat resultImg = srcImg.clone();    Mat_&lt;Vec3b&gt;::iterator it = resultImg.begin&lt;Vec3b&gt;();    Mat_&lt;Vec3b&gt;::iterator itend = resultImg.end&lt;Vec3b&gt;();    for(;it!=itend;it++){        (*it)[0] = 255 - (*it)[0];        (*it)[1] = 255 - (*it)[1];        (*it)[2] = 255 - (*it)[2];    }    showImg(resultImg, &quot;ComplementaryColorTransform&quot;);}</code></pre>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>LeetCode 10. Regular Expression Matching</title>
      <link href="/2019/03/27/LeetCode%2010.%20Regular%20Expression%20Matching/"/>
      <url>/2019/03/27/LeetCode%2010.%20Regular%20Expression%20Matching/</url>
      
        <content type="html"><![CDATA[<p>好久不更博了，一方面因为这学期学的知识自己也没怎么搞明白，没办法整理成博客发出来，另一方面最近生活也不太安宁。感觉自己不能再这么沉沦下去了，以后每周尽量更两篇博客吧，实在没得写就在LeetCode上找个hard题试着AC一下。</p><p>Flag就此立下！</p><p>这次就来看看LeetCode的第10题，题目如下：</p><p>Given an input string (<code>s</code>) and a pattern (<code>p</code>), implement regular expression matching with support for <code>&#39;.&#39;</code> and <code>&#39;*&#39;</code>.</p><pre><code>&#39;.&#39; Matches any single character.&#39;*&#39; Matches zero or more of the preceding element.</code></pre><p>The matching should cover the <strong>entire</strong> input string (not partial).</p><p><strong>Note:</strong></p><ul><li><code>s</code> could be empty and contains only lowercase letters <code>a-z</code>.</li><li><code>p</code> could be empty and contains only lowercase letters <code>a-z</code>, and characters like <code>.</code> or <code>*</code>.</li></ul><p>这一题我在刚做的时候使用的是字符串处理的思路，但是后来发现”.*”这种情况没办法处理，最后使用的是上学期的动态规划的思想才得以解决。</p><pre><code class="c++">#include &lt;iostream&gt;#include &lt;algorithm&gt;using namespace std;class Solution {public:    bool isMatch(string s, string p) {        s = &quot;0&quot; + s;        p = &quot;0&quot; + p;        bool dp[p.length()][s.length()];        dp[0][0] = true;        for (int j = 1; j &lt; s.length(); j++) {            dp[0][j] = false;        }        for (int i = 1; i &lt; p.length(); i++) {            dp[i][0] = false;        }        for (int i = 2; i &lt; p.length() &amp;&amp; p[i] == &#39;*&#39;; i += 2) {            dp[i][0] = true;        }        // 最后一行单独考虑        for(int i = 1; i &lt; p.length() - 1;) {            // 下一个不是&#39;*&#39;            if (p[i + 1] != &#39;*&#39;) {                for(int j = 1; j &lt; s.length(); j++) {                    dp[i][j] = (p[i] == s[j] || p[i] == &#39;.&#39;) ? dp[i-1][j-1] : false;                }                i++;            } else {                for(int j = 1; j &lt; s.length(); j++) {                    dp[i+1][j] = (p[i] == s[j] || p[i] == &#39;.&#39;) ? (dp[i+1][j-1] || dp[i-1][j]) : dp[i-1][j];                }                i += 2;            }        }        if (p[p.length() - 1] != &#39;*&#39;) {            for (int j = 1; j &lt; s.length(); j++) {                dp[p.length() - 1][j] = (p[p.length() - 1] == s[j] || p[p.length() - 1] == &#39;.&#39;) ? dp[p.length() - 2][j-1] : false;            }        }        cout &lt;&lt; endl;        return dp[p.length() - 1][s.length() - 1];    }};</code></pre>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>round(number[, ndigits])</title>
      <link href="/2019/03/27/round(number%5B,%20ndigits%5D)/"/>
      <url>/2019/03/27/round(number%5B,%20ndigits%5D)/</url>
      
        <content type="html"><![CDATA[<p><strong>round函数是Python中常用的四舍五入的函数，但是今天试用了一下发现有点小坑。对0.5进行四舍五入，结果应该为1，可是Python解释器给的结果是：</strong></p><pre><code>&gt;&gt;&gt; round(0.5)0</code></pre><a id="more"></a><p><strong>紧接着我又试了几个数，发现：</strong></p><pre><code>&gt;&gt;&gt; round(1.5)2&gt;&gt;&gt; round(2.5)2</code></pre><p><strong>round(1.5)还算正常，round(2.5)又很奇怪了，然后看了看Python文档，里面这样解释round函数：</strong></p><blockquote><p><strong>For the built-in types supporting round(), values are rounded to the closest multiple of 10 to the power minus ndigits; if two multiples are equally close, rounding is done toward the even choice (so, for example, both round(0.5) and round(-0.5) are 0, and round(1.5) is 2). Any integer value is valid for ndigits (positive, zero, or negative). The return value is an integer if ndigits is omitted or None. Otherwise the return value has the same type as number.</strong></p></blockquote><p><strong>意思是会把这个输入的数保留到小数点后指定的ndigit位数，并且按照一定规则圆整。规则就是看看这个数更靠近左右两端中哪一端，然后就将这个数圆整为这一端，比如0.4就圆整为0，0.6就圆整为1。那如果是像0.5这样的到左右两端距离一样的情况，就圆整到偶数的一端，比如0.5就圆整到0，1.5就圆整到2。</strong></p><p><strong>文档里还写了这么一句话：</strong></p><blockquote><p><strong>Note: The behavior of round() for floats can be surprising: for example, round(2.675, 2) gives 2.67instead of the expected 2.68. This is not a bug: it’s a result of the fact that most decimal fractions can’t be represented exactly as a float. See Floating Point Arithmetic: Issues and Limitations for more information.</strong></p></blockquote><p><strong>就是按照上述规则，round(2.675, 2)的结果应该是2.68，可是实际结果是：</strong></p><pre><code>&gt;&gt;&gt; round(2.675, 2)2.67</code></pre><p><strong>这不是我们写了个bug，这是因为机器在存储浮点数2.675的时候，不会存储到这么精确，存储的数比2.675小一点点，应该差不多是2.674999999这样，所以才会被圆整到2.67，这个问题没法解决。</strong></p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>CTC Loss学习笔记</title>
      <link href="/2019/03/27/CTC%20Loss%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
      <url>/2019/03/27/CTC%20Loss%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</url>
      
        <content type="html"><![CDATA[<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>语音识别时，人说一句“Hello”，尽管发音很标准，但是由于有停顿、换气或是其他原因，音频信息中的“H”音很容易对不上文本信息中的“H”。这就需要预处理对齐问题，但是用人工的方法手动对齐比较音频信息和文本信息，需要耗费大量的人力财力。CTC就是处理这一类对齐问题而生的技术。</p><h2 id="基本过程"><a href="#基本过程" class="headerlink" title="基本过程"></a>基本过程</h2><p>在语音识别中，CTC会逐帧辨别发的什么音。如果通过发音辨别出了一个字母，那么这一帧就标记为这个字母；如果没声音就标记为blank，表示这是两个单词中间的空格；如果分辨不出来是啥，就标记为ϵ (ctc blank)。所以将“Hello”的音频信息进行辨别后，会得到的结果可能会是：“ϵϵHellϵϵlloϵ”，也可能是“Heeϵϵllϵϵlooϵϵ”，还有其他很多种可能。</p><p>ctc的处理过程分为2步：</p><ol><li>将识别结果中相邻的重复字符删掉，那么“ϵϵHellϵϵlloϵ”就变成了“ϵHelϵloϵ”，“Heeϵϵllϵϵlooϵϵ”就变成了“Heϵlϵloϵ”；</li><li>删去ϵ，“ϵHelϵloϵ”和“Heϵlϵloϵ”就都变成了“Hello”。</li></ol><p>我们的目的是求出P(lable|x)，其中x是输入的数据，lable是标签数据，即正确的输出。P(lable|x)表示的是，如果在输入数据为x的条件下，能够正确输出标签数据的概率有多大，这个概率肯定是越大越好，如果P(lable|x)=1，那么就说明百分之百可以正确输出。</p><p>Loss的定义如下，如果P(lable|x)越接近1，Loss就接近于0；如果P(lable|x)越接近0，Loss就会越大：</p><p>$$<br>Loss=-\ln P(lable|x)<br>$$</p><p>P(lable|x)如何计算呢？从上面ctc的处理过程可以看出来，有很多种序列最终都可以处理为标签数据，“ϵϵHellϵϵlloϵ”就是一条可以被处理为“Hello”的序列，记其为seq，那么产生seq的概率有多少呢？这里$y_c^t$表示在第t时间步生成字符c的概率有多少，那么要生成seq这么长的序列，就要把生成每个字符的概率乘起来。</p><p>$$<br>P(seq|x)=y_\epsilon^1 \times y_\epsilon^2 \times y_H^3 \times y_e^4 \times y_l^5 \times y_l^6 \times y_\epsilon^7 \times y_\epsilon^8 \times y_l^9 \times y_l^{10} \times y_o^{11} \times y_\epsilon^{12}<br>$$</p><p>如果再用π来表示一个序列的集合，这个集合中所有的序列和seq一样，经过ctc处理过后，都可以变为标签数据。那么将这个集合中所有序列的概率加起来，就是P(lable|x)。</p><p>$$<br>P(lable|x)=\sum_{\pi}P(\pi|x)<br>$$</p><p>可是，π集合中有多少序列呢，茫茫多的序列都可以转为lable。如果lable是“cat”的话，那么可以转为“cat”的序列数，可以通过下图可以看出来，白色节点表示识别为字母，黑色节点表示识别不出来是个啥，标记为“ϵ”（图片来自网络）：</p><img src="http://pp41mkw5b.bkt.clouddn.com/static/images/ctc_loss_1.png"><p>每一条路径都是一种语音识别的结果，而且此结果可以经由ctc处理后转换为标签数据。这才3个字母，就这么条路径，如果成百上千的单词，一一计算每种可能的话，这个计算量很大。</p><h2 id="使用动态规划优化"><a href="#使用动态规划优化" class="headerlink" title="使用动态规划优化"></a>使用动态规划优化</h2><p>动态规划的思想是自顶向下写一个递归式，然后自底向上算出来。</p><p>如上文所述，在t个时间步走到字符“u”的路线有很多条，如果seq是其中一条路线，那么其概率为：</p>$$P(seq|x)=\prod_{i=1}^{t} y^i_{{seq}_i}$$<p>这里定义一个函数α(t,u)，表示在t个时间步走到字符“u”的概率。用π表示所有可以在t个时间步走到字符“u”的路线集合，那么有：</p>$$\alpha(t,u)=\sum_{\pi}\prod_{i=1}^{t} y^i_{\pi_i}$$<p>再看看刚刚开始那个例子“Hello”，如果当前在第t个时间步，判别成了一个字符“l”，那么在第t-1个时间步上，可以是哪些字符呢？</p><p>这要分2种情况讨论：</p><ol><li>如果“Hello”的第一个“l”，也就是”Hello”标红的那个“l”，那么在第t-1个时间步上，可以是“e”、“ϵ”、“l”三种情况；</li></ol><img src="http://pp41mkw5b.bkt.clouddn.com/static/images/ctc_loss_2.png"><p>所以要求第t个时间步走到“l”的概率，就要先求出在t-1个时间步走到“e”、“ϵ”、“l”的概率，求和之后，再乘以$y_c^t$，即：</p><p>$$<br>\alpha(t,u)=y_u^t[\alpha(t-1,u)+\alpha(t-1,u-1)+\alpha(t-1,u-2)]<br>$$</p><p>这里u-1和u-2表示字符u的上一个字符和上两个字符。</p><ol><li>如果是“Hello”的第二个“l”，也就是“Hello”标红的那个“l”，那么在第t-1个时间步上，只可以是“ϵ”、“l”两种情况。要是算上上面的“l”，那么这两个“l”会合并成1个；如果是在t个时间步上走到了“ϵ”这个字符，那么在t-1个时间步上，也只能是“l”、“ϵ”两种情况。要是也算上上面一个“ϵ”，那么会跨过中间这个“l”，这个字符就不输出了。</li></ol><img src="http://pp41mkw5b.bkt.clouddn.com/static/images/ctc_loss_3.png"><p>所以第t个时间步走到“l”或”ϵ”，只能横着走过来，或从上一个字符过来，概率即：</p><p>$$<br>\alpha(t,u)=y_u^t[\alpha(t-1,u)+\alpha(t-1,u-1)]<br>$$</p><p>这样递归公式就定义好了，再算一下递归式子的底：</p><p>$$<br>\alpha(1,1)=y_\epsilon^1<br>$$</p><p>$$<br>\alpha(1,2)=y_h^1<br>$$</p><p>$$<br>\alpha(1,u)=0 \quad u&gt;2<br>$$</p><p>从这个底开始，使用递推公式自底向上的计算，直至算出$\alpha(T,lable)+\alpha(T,lable-1)$，T表示总时间步，所有可以经过ctc转化为“Hello”的序列，最后一个字符可以是“ϵ”也可以是“o”。label表示所最后一个字符是“ϵ”，label-1表示最后一个字符是“o”，这样走出的路线都可以经过ctc转化为“Hello”。</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>科大软院 - 人工智能期中考试复习</title>
      <link href="/2019/03/27/1%E7%A7%91%E5%A4%A7%E8%BD%AF%E9%99%A2%20-%20%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E6%9C%9F%E4%B8%AD%E8%80%83%E8%AF%95%E5%A4%8D%E4%B9%A0/"/>
      <url>/2019/03/27/1%E7%A7%91%E5%A4%A7%E8%BD%AF%E9%99%A2%20-%20%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E6%9C%9F%E4%B8%AD%E8%80%83%E8%AF%95%E5%A4%8D%E4%B9%A0/</url>
      
        <content type="html"><![CDATA[<p>中国科学技术大学软件学院 人工智能2018年秋课程期中考试复习🍰</p><a id="more"></a><h2 id="1、机器学习的定义"><a href="#1、机器学习的定义" class="headerlink" title="1、机器学习的定义"></a><strong>1、机器学习的定义</strong></h2><p><strong>对于某类任务T和性能度量P，一个计算机程序被认为可以从经验E中学习是指，经过经验E改进后，它在任务T上由性能度量P衡量的性能有所提升。</strong></p><p><strong>任务T：Testing Set - 测试集</strong></p><p><strong>性能度量P：Loss Function - 损失函数</strong></p><p><strong>经验E：Training Set - 训练集</strong></p><h2 id="2、Loss-Function-Cost-Function-损失函数"><a href="#2、Loss-Function-Cost-Function-损失函数" class="headerlink" title="2、Loss Function/Cost Function - 损失函数"></a><strong>2、Loss Function/Cost Function - 损失函数</strong></h2><p><strong>假设函数：</strong><br>$$<br>h_{w,b}(x) = wx+b<br>$$<br><strong>在回归任务中，多使用均方误差作为损失函数：</strong><br>$$<br>L(w,b) = \frac{1}{2m}\sum_{i=1}^{m}(h_{w,b}(x^{(i)}) - \hat{y}^{(i)})^2<br>$$<br><strong>在分类任务中，多使用交叉熵作为损失函数：</strong><br>$$<br>L(w,b) = \frac{1}{m}\sum_{i=1}^{m}[-\hat{y}^{(i)}\log(h_{w,b}(x^{(i)})) - (1-\hat{y}^{(i)})\log(1-h_{w,b}(x^{(i)}))]<br>$$</p><h2 id="3、Sigmoid-Function和Softmax-Function"><a href="#3、Sigmoid-Function和Softmax-Function" class="headerlink" title="3、Sigmoid Function和Softmax Function"></a><strong>3、Sigmoid Function和Softmax Function</strong></h2><p><strong>Sigmoid Function不具体表示哪一个函数，而是表示一类S型函数，常用的有逻辑函数σ(z)：</strong><br>$$<br>\sigma(z) = \frac{1}{1+e^{-z}}<br>$$<br><strong>Softmax Function，或称归一化指数函数，是逻辑函数的一种推广。它能将一个含任意实数的K维向量z “压缩”到另一个K维实向量 σ(z)  中，使得每一个元素的范围都在(0,1) 之间，并且所有元素的和为1。该函数的形式通常按下面的式子给出：</strong><br>$$<br>\sigma(z)_{j} = \frac{e^{z_{j}}}{\sum_{k=1}^{K}e^{z_{k}}} \quad j = 1,…,K<br>$$</p><h2 id="4、在Logistic-Regression中，为何使用Cross-Entropy作为损失函数而不使用MSE"><a href="#4、在Logistic-Regression中，为何使用Cross-Entropy作为损失函数而不使用MSE" class="headerlink" title="4、在Logistic Regression中，为何使用Cross Entropy作为损失函数而不使用MSE"></a><strong>4、在Logistic Regression中，为何使用Cross Entropy作为损失函数而不使用MSE</strong></h2><p><strong>Logistic Regression的假设函数如下：</strong><br>$$<br>\sigma(z) = \frac{1}{1+e^{-z}} \quad z(x) = wx+b<br>$$</p><p><strong>σ(z)分别对w和b求导，结果为：</strong><br>$$<br>\frac{\partial \sigma(z)}{\partial w} = \frac{\mathrm{d} \sigma(z)}{\mathrm{d} z} \frac{\partial z}{\partial w}= \sigma(z)(1-\sigma(z))*x<br>$$</p><p>$$<br>\frac{\partial \sigma(z)}{\partial b} = \frac{\mathrm{d} \sigma(z)}{\mathrm{d} z} \frac{\partial z}{\partial b}= \sigma(z)(1-\sigma(z))<br>$$</p><p><strong>如果使用MSE作为损失函数的话，那写出来是这样的：</strong><br>$$<br>L(w,b) = \frac{1}{2m}\sum_{i=1}^{m}(\sigma_{w,b}(x^{(i)}) - \hat{y}^{(i)})^2<br>$$<br><strong>当我们使用梯度下降来进行凸优化的时候，分别需要计算L(w,b)对w和b的偏导数：</strong></p><p>$$<br>\frac{\partial L(w,b)}{\partial w} = \frac{1}{m}\sum_{i=1}^{m}(\sigma_{w,b}(x^{(i)}) - \hat{y}^{(i)})\sigma_{w,b}(x^{(i)})(1-\sigma_{w,b}(x^{(i)}))x^{(i)}<br>$$</p><p>$$<br>\frac{\partial L(w,b)}{\partial b} = \frac{1}{m}\sum_{i=1}^{m}(\sigma_{w,b}(x^{(i)}) - \hat{y}^{(i)})\sigma_{w,b}(x^{(i)})(1-\sigma_{w,b}(x^{(i)}))<br>$$</p><p><strong>所以在σ(x)接近于1或者0的时候，也就是预测的结果和真实结果很相近或者很不相近的时候，σ(x)和1-σ(x)中总有一个会特别小，这样会导致梯度很小，从而使得优化速度大大减缓。</strong></p><p><strong>而当使用Cross Entropy作为损失函数时，损失函数为：</strong><br>$$<br>L(w,b) = \frac{1}{m}\sum_{i=1}^{m}(-\hat{y}^{(i)}\log(\sigma_{w,b}(x^{(i)})) - (1-\hat{y}^{(i)})\log(1-\sigma_{w,b}(x^{(i)})))<br>$$</p><p><strong>L(w,b)分别对w和b求偏导，结果如下：</strong><br>$$<br>\frac{\partial L(w,b) }{\partial w}= \frac{1}{m}\sum_{i=1}^{m}(\sigma_{w,b}(x^{(i)})-\hat{y}^{(i)})x^{(i)}<br>$$</p><p>$$<br>\frac{\partial L(w,b) }{\partial b}= \frac{1}{m}\sum_{i=1}^{m}(\sigma_{w,b}(x^{(i)})-\hat{y}^{(i)})<br>$$</p><p><strong>这样梯度始终和预测值与真实值之差挂钩，预测值与真实值偏离很大时，梯度也会很大，偏离很小时，梯度会很小。所以我们更倾向于使用Cross Entropy而不使用MSE。函数图如下所示：</strong><br><img src="http://pp41mkw5b.bkt.clouddn.com/static/images/1_1.png"></p><h2 id="5、一堆优化方法"><a href="#5、一堆优化方法" class="headerlink" title="5、一堆优化方法"></a><strong>5、一堆优化方法</strong></h2><p><strong>这堆优化方法只有一个目标：寻求合适的w和b（两个参数情况），使得L(w,b)损失函数的值最小。</strong></p><h3 id="1-Gradient-Descent-梯度下降"><a href="#1-Gradient-Descent-梯度下降" class="headerlink" title="(1) Gradient Descent - 梯度下降"></a><strong>(1) Gradient Descent - 梯度下降</strong></h3><p><strong>如果需要找到一个函数的局部极小值，必须朝着函数上当前点所对应梯度（或者是近似梯度）的反方向，前进规定步长的距离进行迭代搜索。</strong></p><p>$$<br>w’ \leftarrow w - \eta \frac{\partial L(w,b)}{\partial w}<br>$$</p><p>$$<br>b’ \leftarrow b - \eta \frac{\partial L(w,b)}{\partial b}<br>$$</p><p><strong>tips: 这里不可以将更新好的w’代入到L(w,b)中然后计算b’，参数w和b都必须等计算好后一起更新。</strong></p><p><strong>η代表学习率，部分决定了每一次更新的步长大小，如果学习率太低会导致更新十分缓慢，学习率太高又会导致步长太大全场乱跑。</strong></p><h4 id="为什么要以梯度的反方向为更新方向？"><a href="#为什么要以梯度的反方向为更新方向？" class="headerlink" title="为什么要以梯度的反方向为更新方向？"></a><strong>为什么要以梯度的反方向为更新方向？</strong></h4><p><strong>因为梯度方向是函数方向导数最大的方向，所以沿着梯度方向的反方向更新的话，函数下降的变化率最大。（感谢zzj在评论中指正）</strong></p><h3 id="2-Stochastic-Gradient-Descent-随机梯度下降"><a href="#2-Stochastic-Gradient-Descent-随机梯度下降" class="headerlink" title="(2) Stochastic Gradient Descent - 随机梯度下降"></a><strong>(2) Stochastic Gradient Descent - 随机梯度下降</strong></h3><p><strong>随机梯度下降的损失函数要这样定义：</strong></p><p>$$<br>L^{(i)}(w,b) = \frac{1}{2}(h_{w,b}(x^{(i)}) - \hat{y}^{(i)})^2<br>$$</p><p><strong>对比梯度下降的损失函数，发现这里少了求和以及求平均值的过程，因为这里只有一个样本作为参考，这个损失函数也是关于这一个样本的损失函数。</strong></p><p><strong>可以这样来理解：训练集里有20个样本，现在我就当作我只拥有这20个样本的其中一个样本，然后使用这一个样本更新参数，然后再挑另一个样本，更新参数，以此类推，直到所有样本都被用完后，这一轮随机梯度下降就结束了。</strong></p><p><strong>和梯度下降比较一下，随机梯度下降的好处是：梯度下降每次更新都用到了所有的样本，也就是使用所有样本的信息进行一次参数更新。而随机梯度下降每次更新只用到了一个样本，如果这个训练集有m个样本，那么梯度下降更新一次参数，随机梯度下降已经更新了m次参数了。所以随机梯度下降的更新频率是梯度下降的m倍，更新速度更快；</strong></p><p><strong>而随机梯度下降所带来的坏处是：随机梯度下降的更新只参考了一个样本，这种参考有点管中窥豹了，是不可能顾全大局的，所以更新时候的抖动现象很明显，就是参数的前进方向乱七八糟的，但是总体来说还是向着最低点前进。</strong></p><h3 id="3-Mini-batch-Gradient-Descent-Mini-batch梯度下降"><a href="#3-Mini-batch-Gradient-Descent-Mini-batch梯度下降" class="headerlink" title="(3) Mini-batch Gradient Descent - Mini-batch梯度下降"></a><strong>(3) Mini-batch Gradient Descent - Mini-batch梯度下降</strong></h3><p><strong>Mini-batch梯度下降是梯度下降和随机梯度下降的中和版本，随机梯度下降每次更新只考虑一个样本，梯度下降每次更新考虑所有样本，而Mini-batch梯度下降每次更新所考虑的样本是可以被指定的，如果总共有m个样本，那就可以在1~m中任意指定。</strong></p><p><strong>如果每次更新时所参考的样本数合适，那么既兼顾了随机梯度下降更新速度快的特性，又兼顾了梯度下降更新的稳定性。</strong></p><p><strong>可以说梯度下降和随机梯度下降都是Mini-batch梯度下降的一个特例，使用梯度下降时，指定每次更新参考全部样本，而使用随机梯度下降时，每次更新只参考1个样本。</strong></p><p><strong>注意：虽然随机梯度下降和Mini-batch梯度下降都是基于一部分数据进行参数更新，但是更新完后查看损失函数是基于全部训练数据所得出的训练误差。</strong></p><h3 id="4-Adagrad算法"><a href="#4-Adagrad算法" class="headerlink" title="(4) Adagrad算法"></a><strong>(4) Adagrad算法</strong></h3><p><strong>像Adagrad这一类自适应算法都是使用了自适应的学习率，他们都有一个基本思路：在整个训练过程中使用同一个学习率是不合适的，因为在训练开始时，损失值肯定是比较大的，所以需要较大的学习率，而训练快要结束时，越来越接近最低点了，此时需要较小学习率。所以这类算法会依据某些因素，在迭代过程中，逐渐减小学习率。</strong></p><p><strong>比如可以按下面这个公式来设计自适应的学习率，其中t代表了迭代次数：</strong></p><p>$$<br>\eta^t=\frac{\eta}{\sqrt{t+1}}<br>$$</p><p><strong>这样学习率就会根据迭代次数来放缓学习率，从而达到学习率越来越小的目的。但是这样还是不够的，因为还要考虑到具体的函数情况。Adagrad算法不仅要求学习率跟着迭代次数变化，就是按上面的公式算出$\eta^t$，还要再除以之前所有梯度的平方平均数，$g^t$代表了第t次迭代时的梯度。</strong></p><p>$$<br>w^1 \leftarrow w^0 - \frac{\eta^0}{\sigma^0}g^0 \qquad \sigma^0 = \sqrt{(g^0)^2}<br>$$</p><p>$$<br>w^2 \leftarrow w^1 - \frac{\eta^1}{\sigma^1}g^1 \qquad \sigma^1 = \sqrt{\frac{1}{2}[(g^0)^2+(g^1)^2]}<br>$$</p><p>$$<br>w^3 \leftarrow w^2 - \frac{\eta^2}{\sigma^2}g^2 \qquad \sigma^2 = \sqrt{\frac{1}{3}[(g^0)^2+(g^1)^2 + (g^2)^2]}<br>$$</p><p>$$<br>……<br>$$</p><p>$$<br>w^{t+1} \leftarrow w^t - \frac{\eta^t}{\sigma^t}g^t \qquad \sigma^t = \sqrt{\frac{1}{t+1}\sum_{i=0}^{t}(g^i)^2}<br>$$</p><p><strong>其中有$\eta^t=\frac{\eta}{\sqrt{t+1}}​$代入到最后一个式子就可以得到：</strong><br>$$<br>w^{t+1} \leftarrow w^t - \frac{\frac{\eta}{\sqrt{t+1}}}{\sqrt{\frac{1}{t+1}\sum_{i=0}^{t}(g^i)^2}}g^t<br>$$</p><p><strong>同时约去$\frac{1}{\sqrt{t+1}}$后就可以得到：</strong></p><p>$$<br>w^{t+1} \leftarrow w^t - \frac{\eta}{\sqrt{\sum_{i=0}^{t}(g^i)^2}}g^t<br>$$</p><p><strong>这就是Adagrad算法的公式了，我们可以看到这个式子中，学习率是会一直除以前面所有梯度的平方和再开根号的，这一定是一个大于0的数，所以学习率会越来越小。但是防止一开始的时候梯度就是0，如果让分母变为0会导致错误的，所以后面还要跟一个很小的正数$\epsilon​$，最终的式子是这样的：</strong><br>$$<br>w^{t+1} \leftarrow w^t - \frac{\eta}{\sqrt{\sum_{i=0}^{t}(g^i)^2+\epsilon}}g^t<br>$$</p><p><strong>Adagrad算法也有很多不足：</strong></p><p><strong>a) 如果初始的学习率设置过大的话，这个学习率要除以一个较大梯度，那么此算法会对梯度的调节太大；</strong><br><strong>b) 在训练的中后期，分母上梯度平方的累加将会越来越大，使$gradient\to0$，使得训练提前结束。</strong></p><h3 id="5-RMSprop算法"><a href="#5-RMSprop算法" class="headerlink" title="(5) *RMSprop算法"></a><strong>(5) *RMSprop算法</strong></h3><p><strong>我感觉最多考到Adagrad算法就行了，RMSprop应该考不到。</strong></p><p><strong>在凸优化问题上，Adagrad算法具有很好的效果，但是在神经网络情况下，很多问题都是非凸优化问题，即损失函数有很多局部最小值，有了Adagrad算法的改进版RMSprop算法，RMSprop算法就像是真实物理世界中一个小球在山坡上向下滑，如果滑落到一个山谷中，小球是不会立刻停在这里的，由于具有惯性的原因，小球会继续向前冲，如果惯性足够的话，可能会再次冲出山头，更有可能会落到另一个更低的山谷中。而传统的梯度下降法只会落在一个山谷中，没有机会冲出来。</strong><br>$$<br>w^1 \leftarrow w^0 - \frac{\eta}{\sigma^0}g^0 \qquad \sigma^0 = g^0<br>$$</p><p>$$<br>w^2 \leftarrow w^1 - \frac{\eta}{\sigma^1}g^1 \qquad \sigma^1 = \sqrt{\alpha(\sigma^0)^2 + (1-\alpha)(g^1)^2}<br>$$</p><p>$$<br>w^3 \leftarrow w^2 - \frac{\eta}{\sigma^2}g^2 \qquad \sigma^2 = \sqrt{\alpha(\sigma^1)^2 + (1-\alpha)(g^2)^2}<br>$$</p><p>$$<br>……<br>$$</p><p>$$<br>w^{t+1} \leftarrow w^t - \frac{\eta}{\sigma^t}g^t \qquad \sigma^t = \sqrt{\alpha(\sigma^{t-1})^2 + (1-\alpha)(g^t)^2}<br>$$</p><p><strong>Adagrad和RMSprop算法这两个算法很相近，不同之处在于RMSprop算法增加了一个衰减系数α来控制历史信息的获取多少。</strong></p><h2 id="6、Cross-Validation-交叉验证"><a href="#6、Cross-Validation-交叉验证" class="headerlink" title="6、Cross Validation - 交叉验证"></a><strong>6、Cross Validation - 交叉验证</strong></h2><p><strong>将数据集D划分成k个大小相似的互斥子集，每次用k-1个子集作为训练集，余下的子集做测试集，最终返回k个训练结果的平均值。交叉验证法评估结果的稳定性和保真性很大程度上取决于k的取值。</strong></p><img src="http://pp41mkw5b.bkt.clouddn.com/static/images/1_2.png"><h3 id="为什么要用交叉验证-Cross-Validation）"><a href="#为什么要用交叉验证-Cross-Validation）" class="headerlink" title="为什么要用交叉验证(Cross-Validation）"></a><strong>为什么要用交叉验证(Cross-Validation）</strong></h3><p><strong>a) 交叉验证用于评估模型的预测性能，尤其是训练好的模型在新数据上的表现，可以在一定程度上减小过拟合；</strong><br><strong>b) 还可以从有限的数据中获取尽可能多的有效信息。</strong></p><p><strong>注意：交叉验证使用的仅仅是训练集！</strong></p><h2 id="7、偏差、方差、噪声以及泛化误差"><a href="#7、偏差、方差、噪声以及泛化误差" class="headerlink" title="7、偏差、方差、噪声以及泛化误差"></a><strong>7、偏差、方差、噪声以及泛化误差</strong></h2><h3 id="1-偏差"><a href="#1-偏差" class="headerlink" title="(1) 偏差"></a><strong>(1) 偏差</strong></h3><img src="http://pp41mkw5b.bkt.clouddn.com/static/images/1_3.png"><p><strong>偏差bias： 期望预测与真实标记的误差，偏差越大偏离理论值越大。</strong></p><p><strong>上面的ppt里，左边的图模型阶数小，所以不可能很好的拟合真实情况，所作出的预测与真实情况偏离程度大，所以偏差就大；而右边的图里模型很复杂，足够模拟出真实情况，所以与真实情况偏离程度小，偏差就小。</strong></p><p><strong>在一个训练集$D$上模型$f$对测试样本$x$预测输出为$f(x;D)$, 那么学习算法$f$对测试样本$x$的期望预测为：</strong></p><p>$$<br>\bar{f}(x)=E_D[f(x;D)]<br>$$<br><strong>这里用偏差的平方来表示偏差的计算公式：</strong></p><p>$$<br>Bias^2(x)=(\bar{f}(x)-\hat{y})^2<br>$$</p><h3 id="2-方差"><a href="#2-方差" class="headerlink" title="(2) 方差"></a><strong>(2) 方差</strong></h3><img src="http://pp41mkw5b.bkt.clouddn.com/static/images/1_4.png"><p><strong>方差variance：预测模型的离散程度，方差越大离散程度越大。</strong></p><p><strong>就像上面ppt的左图，因为模型阶数小，所以模型都很集中；而右边的模型阶数大，有时能拟合的很好，有时拟合的不好，不稳定因素太大了。</strong></p><p><strong>使用样本数相同的不同训练集产生的方差为:</strong></p><p>$$<br>var(x)=E_D[(f(x;D)-\bar{f}(x))^2]<br>$$</p><h3 id="3-噪声"><a href="#3-噪声" class="headerlink" title="(3) *噪声"></a><strong>(3) *噪声</strong></h3><p><strong>不可能考</strong></p><p><strong>噪声为真实标记与数据集中的实际标记间的偏差$y_D$表示在数据集中的标记，$\hat{y}$表示真实标记，这两个可能不等）：</strong></p><p>$$<br>\epsilon=E_D[(y_D-\hat{y})^2]<br>$$</p><h3 id="4-泛化误差"><a href="#4-泛化误差" class="headerlink" title="(4) *泛化误差"></a><strong>(4) *泛化误差</strong></h3><p><strong>也不可能考</strong></p><p><strong>学习算法的预测误差, 或者说泛化误差(generalization error)可以分解为三个部分: 偏差(bias), 方差(variance) 和噪声(noise). 在估计学习算法性能的过程中, 我们主要关注偏差与方差。因为噪声属于不可约减的误差 (irreducible error)。</strong></p><p><strong>下面来用公式推导泛化误差与偏差与方差, 噪声之间的关系。</strong></p><p><strong>以回归任务为例, 学习算法的平方预测误差期望为：</strong></p><p>$$<br>Err(x)=E_D[(y_D-f(x;D))^2]<br>$$</p><p><strong>对算法的期望泛化误差进行分解，就会发现 泛化误差=偏差的平方+方差+噪声:</strong></p><img src="http://pp41mkw5b.bkt.clouddn.com/static/images/1_5.png"><img src="http://pp41mkw5b.bkt.clouddn.com/static/images/1_6.png"> <h2 id="8、欠拟合和过拟合"><a href="#8、欠拟合和过拟合" class="headerlink" title="8、欠拟合和过拟合"></a><strong>8、欠拟合和过拟合</strong></h2><p><strong>欠拟合：模型拟合不够，在训练集上拟合情况很差。往往会出现偏差大、方差小的情况；</strong></p><p><strong>过拟合：模型过度拟合，在训练集上拟合情况很好，但是在测试集上拟合情况很差。往往会出现偏差小、方差大的情况。</strong></p><p><strong>出现欠拟合时，解决办法有：</strong></p><p><strong>a) 增加新特征，可以考虑加入特征组合、高次特征，来增大假设空间;</strong><br><strong>b) 尝试非线性模型，比如核SVM 、决策树、DNN等模型;</strong><br><strong>c) 如果有正则项可以减小正则项参数λ；</strong><br><strong>d) Boosting，Boosting 往往会有较小的 Bias，比如 Gradient Boosting 等。</strong></p><p><strong>出现过拟合时，解决办法有：</strong></p><p><strong>a) 交叉检验，通过交叉检验得到较优的模型参数;</strong><br><strong>b) 特征选择，减少特征数或使用较少的特征组合，对于按区间离散化的特征，增大划分的区间;</strong><br><strong>c) 正则化，常用的有 L1、L2 正则。而且 L1正则还可以自动进行特征选择;</strong><br><strong>d) 如果有正则项则可以考虑增大正则项参数 λ;</strong><br><strong>e) 增加训练数据可以有限的避免过拟合;</strong><br><strong>f) Bagging，将多个弱学习器Bagging 一下效果会好很多，比如随机森林等。</strong></p><h2 id="9、L1范数和L2范数"><a href="#9、L1范数和L2范数" class="headerlink" title="9、L1范数和L2范数"></a><strong>9、L1范数和L2范数</strong></h2><p><strong>本来以为会很快写完这个部分的，没想到这里的知识点看了一晚上，更没想到这里的知识完完整整拿出来，完全可以写一篇长长的博文。如果想好好学习这里的知识的话，我推荐<a href="https://blog.csdn.net/jinping_shi/article/details/52433975" target="_blank" rel="noopener">这个博客</a>，或者是周老师的西瓜书第252页。这里我就介绍一点最基本的知识了。</strong></p><p><strong>L1范数：向量元素绝对值之和，即：</strong></p><p>$$<br>\left | \theta \right |_1=\sum_{i=1}^{n}\left | \theta_i \right |<br>$$</p><p><strong>L2范数：这里我查了好久的资料，我发现网上所有的资料，包括周老师的西瓜书以及邱锡鹏教授的《神经网络与深度学习》都是说，L2范数是各个元素的平方和再求平方根，即：</strong></p><p>$$<br>\left | \theta \right |_2=\sqrt{\sum_{i=1}^{n}\theta_i^2}<br>$$</p><p><strong>但是吴恩达教授、李宏毅教授课上讲的版本，以及我在学校课上（我们学校的课不就是照搬李宏毅教授的课嘛）所记录的版本，都是写的L2范数为各个元素的平方和，不再求平方根，即：</strong></p><p>$$<br>\left | \theta \right |_2=\sum_{i=1}^{n}\theta_i^2<br>$$</p><p><strong>吴恩达教授：</strong></p><img src="http://pp41mkw5b.bkt.clouddn.com/static/images/1_7.png"><p><strong>李宏毅教授：</strong></p><img src="http://pp41mkw5b.bkt.clouddn.com/static/images/1_8.png"><p><strong>我的笔记就不拿出来了，和前两位的差不多。在这里我还是使用这个不开根号的版本。</strong></p><h3 id="1-L1范数的作用"><a href="#1-L1范数的作用" class="headerlink" title="(1) L1范数的作用"></a><strong>(1) L1范数的作用</strong></h3><p><strong>L1范数可以产生稀疏权值矩阵，一定程度上也可以防止过拟合。</strong></p><p><strong>稀疏权值矩阵的意思是，这个矩阵中大部分元素都是0，只有很小一部分元素不为0。试想一下当我们在看周杰伦演唱会时，只会把注意力放在周董身上，不太会关注伴舞小姐姐，更不可能去关注旁边又矮又胖的音响（这一句考试别写）。而在计算机视觉领域也一样，传进来一张图片，这个图片有很多很多的像素，但是机器真正要关注的只有其中一部分元素，比如一张田地里的农民，或是草地里的狗狗之类的，其他不重要的信息就直接不看了，所以和主题无关的信息都会乘上0，有意义的信息才会保留。自然语言处理也是一样，有很多无意义的词都会乘上0，只挑选有意义的信息保留下来。关于具体怎么实现的不讲了，去看周老师的西瓜书吧。</strong></p><h3 id="2-L2范数的作用"><a href="#2-L2范数的作用" class="headerlink" title="(2) L2范数的作用"></a><strong>(2) L2范数的作用</strong></h3><p><strong>L2范数主要用于防止模型过拟合。</strong></p><p><strong>L2范数比较重要一点，L2范数的作用是权值衰减，缩小各个权值，使得函数尽可能比不加L2范数平滑很多，增大模型的泛化能力。如果损失函数加上L2范数后，是这样：</strong></p><p>$$<br>L(\theta) = \frac{1}{2m}[\sum_{i=1}^{m}(h_{\theta}(x^{(i)}) - \hat{y}^{(i)})^2 + \lambda\sum_{j=1}^{n}\theta_j^2]<br>$$</p><p><strong>当使用梯度下降时，得出的式子是这样的：</strong><br>$$<br>\theta_j’ \leftarrow (1-\eta\frac{\lambda}{m})\theta_j - \eta\frac{1}{m} \sum_{i=1}^{m}(h_{\theta}(x^{(i)}) - \hat{y}^{(i)})x^{(i)}<br>$$</p><p><strong>每次参数更新时，都要先把原来的参数乘上一个介于0和1的数，所以参数都会先缩小一点点，再进行更新。一般来说$1-\eta\frac{\lambda}{m}$都会是一个很接近1的数，别看一个数打九九折后没什么变化，可是迭代次数多了后，这个权值是会衰减的很严重的。通过这种方法会有效降低权值，使得函数更为平滑，使得模型的泛化能力更强。</strong></p><h2 id="10、优化技巧"><a href="#10、优化技巧" class="headerlink" title="10、优化技巧"></a><strong>10、优化技巧</strong></h2><p><strong>训练集中常常有些特征的范围差别很大，这样会导致在优化时，不同的参数优化速度差别很大。比如房子的大小从10~2000平米都有可能，而房间数只能处在1~10这个范围内，在进行优化时，房间数的参数很快就找到了最低点，而房子大小的参数还离最低点很远，这样的话，房间数的参数就在最低点来回波动，等待房子大小的参数优化好。如果能尽量让所有参数同时优化好，那么会大大提高优化速度。</strong></p><img src="http://pp41mkw5b.bkt.clouddn.com/static/images/1_优化.png"><h3 id="1-Feature-Scaling-特征缩放-归一化"><a href="#1-Feature-Scaling-特征缩放-归一化" class="headerlink" title="(1) Feature Scaling - 特征缩放/归一化"></a><strong>(1) Feature Scaling - 特征缩放/归一化</strong></h3><p><strong>归一化的思路是：让输入的值减去样本中最小的值，然后除以样本范围（也就是样本最大值减去样本最小值），这样会使得结果永远在0~1的范围内，所有特征参数差不多一个速度优化到最低点。式子如下：</strong></p><p>$$<br>x’=\frac{x-min}{max-min}<br>$$</p><h3 id="2-Mean-Normalization-均值标准化"><a href="#2-Mean-Normalization-均值标准化" class="headerlink" title="(2) Mean Normalization - 均值标准化"></a><strong>(2) Mean Normalization - 均值标准化</strong></h3><p><strong>均值标准化的思路是：让输入的值减去样本平均数μ，再除以样本标准差σ。经过这样的处理，数据的均值会是0，大小在-1~1之间。均值标准化和归一化一样，也有去除不同特征量纲不同的问题，另外机器学习中很多函数如Sigmoid、Tanh、Softmax等都以0为中心左右分布，所以数据以0为中心左右分布会带来很多便利。</strong><br>$$<br>{x}’=\frac{x-\mu}{\sigma}<br>$$</p><h2 id="11、怎么调节学习率"><a href="#11、怎么调节学习率" class="headerlink" title="11、怎么调节学习率"></a><strong>11、怎么调节学习率</strong></h2><p><strong>当我们在训练过程中，发现loss下降的很慢时，可以适当增大学习率；发现loss不降反增的时候，要降低学习率。</strong></p><p><strong>如果我们使用的是Adagrad算法，那么一开始学习率可以设置的相对大一点。</strong></p><h2 id="12、逻辑回归的局限性-深度神经网络的兴起导火索"><a href="#12、逻辑回归的局限性-深度神经网络的兴起导火索" class="headerlink" title="12、逻辑回归的局限性 - 深度神经网络的兴起导火索"></a><strong>12、逻辑回归的局限性 - 深度神经网络的兴起导火索</strong></h2><p><strong>逻辑回归不可以直接处理线性不可分的问题，例如下图所示的异或问题。处理方法是先通过一个函数，将原来的值投影转换，变成线性可分问题，再使用逻辑回归来处理。这一步叫做特征变换，先进行特征变换，再进行逻辑回归，这就是两层神经网络的雏形，也是神经网络的兴起的导火索。</strong></p><img src="http://pp41mkw5b.bkt.clouddn.com/static/images/1深度学习导火索.jpg">]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>动态规划 - Dynamic Programming</title>
      <link href="/2019/03/27/4%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92%20-%20Dynamic%20Programming/"/>
      <url>/2019/03/27/4%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92%20-%20Dynamic%20Programming/</url>
      
        <content type="html"><![CDATA[<blockquote><p>Those who cannot remember the past are condemned to repeat.</p><p>-Dynamic Programming</p></blockquote><a id="more"></a><p>今天的算法课讲的就是动态规划，虽早已久仰大名，但始终不太懂背后原理。听完课后赶紧把今天学到的东西记下来。</p><p>动态规划和分治法有类似之处，他们都是通过组合子问题的解来求解原问题。不同之处在于，分治法常常用于将原问题划分为几个<strong>互不相交</strong>的子问题，如果划分后，有很多<strong>完全相同</strong>的子问题，那就使用动态规划的思路比较好。例如快速排序，将一段数组以枢纽值为界一分为二，再将这两段分别排序。将分出来的两段数组分别排序就是互不相交的两个子问题，可以使用分治法来解决。再如求斐波那契数列的第n项问题，我们知道斐波那契数列的规律是<br>$$<br>F(0) = 0 \quad F(1) = 1 \quad F(n) = F(n - 1) + F(n - 2) (n &gt;= 2)<br>$$<br>我们发现求F(n)需要计算F(n-1)和F(n-2)，可是当计算F(n-1)和F(n-2)时，都需要计算F(n-3)，这样就造成了重复计算，大幅降低了效率，而动态规划算法的目的就是避免此类重复计算。</p><p>去年暑假，我好好思考了一下上台阶问题：</p><blockquote><p>有100级台阶，每次只允许上1级台阶或上2级台阶，若要求上完全部台阶，共有多少种上法？</p></blockquote><p>第一次看到还以为是组合数学问题，后来也没做出来。再一想，要不直接枚举吧，那这样的数据规模是惊人的，是指数级的时间复杂度。</p><p>emmm~我们考虑一下分治法吧。假设一下，现在已经站在了第100层台阶上，回忆一下刚刚最后一步我是怎么上来着的。我最后一步可以是从98层一步跨上来的，也可以是从99层踩上一级台阶上来。这时让我们时光倒流，我们可以选择最后一步从98层跨两级上来，也可以选择从99层爬一级上来。</p><p>现在我们将这两种可能分开讨论，如果我限定最后一步只能走一步，那么之前我就必须上到99层，而99层到100层只有1条路可走，上到100层的上法就等于上到99层的上法，所以我现在只要得知上到99层有多少种上法，就知道了上到100层有多少种上法；同理，如果我限定最后一步必须跨两步，那么我之前就必须上到98层，所以我现在只要得知上到98层有多少种上法，98层到100层也只有跨两级这一条路，所以上到100层的上法就等于上到98层的上法了。</p><p>现实里，最后一步可以跨两级，也可以只爬一级，所以上到100层的上法，应该等于上到98层的上法加上上到99层的上法。如果用函数F(n)表示上到第n层一共有多少种上法，那么就有F(100) = F(99) + F(98)，接下来也有F(99) = F(98) + F(97)，F(98) = F(97) + F(96)……。</p><p>这样问题就很简单了，只要这样不断递归下去，总会递归到一个终点，这个终点就是F(1)和F(2)，上一层台阶有多少种上法呢，显然除了一步跨上去没别的方法了吧，所以F(1) = 1；上两层台阶呢？一步一步爬，或是一步跨两个，F(2)应该等于2。那么现在的递归式应该是：<br>$$<br>F(1) = 1 \quad F(2) = 2 \quad F(n) = F(n - 1) + F(n - 2) (n &gt; 2)<br>$$<br>将n取值为100，这样我们就可以算出结果了，用c++写出的代码如下：</p><pre><code class="c++">#include &lt;iostream&gt;using namespace std;long F(int n) {    if (n == 1) {        return 1;    } else if (n == 2) {        return 2;    } else {        return F(n - 1) + F(n - 2);    }}int main() {    long result = F(100);    cout &lt;&lt; result;    return 0;}</code></pre><p>这个代码跑很久都是跑不出来的，就是因为重复计算的部分太多了，详细讲来，如果我们要算f(100)，那么我们需要先得知f(99)和f(98)，然后想要得知f(99)和f(98)，都需要先算出f(97)，这样f(97)就计算了两遍，造成了重复计算，浪费了大量时间。上面代码中包含大量重复计算的内容，而动态规划算法就很好的解决了重复计算的问题。</p><p>现在我们不再从100层开始逐层向下递归，而是从第一层开始逐层向上走。什么意思呢？正如上面提到的问题，如果从下往上计算的话，我们先算出了f(97)的值，然后在计算f(99)和f(98)的时候，就可以共享一个计算成果，不需要花两倍的时间来计算。</p><p>从底层开始计算时，我们首先得知f(1) = 1以及f(2) = 2，根据F(n) = F(n - 1) + F(n - 2)的公式，可以很轻松算出F(3) = 3，F(4) = 5，然后继续向下推，直到n到100就可以得到结果。用代码实现的话，可以新开一个数组array，array[n]内存储了F(n)的结果。</p><pre><code class="c++">#include &lt;iostream&gt;#include &lt;vector&gt;using namespace std;long F(int n) {    vector&lt;long&gt; array(n + 1, 0);    array[1] = 1;    array[2] = 2;    for (int i = 3; i &lt;= n; i++)        array[i] = array[i - 1] + array[i - 2];    return array[n];}int main() {    long result = F(100);    cout &lt;&lt; result;    return 0;}</code></pre><p>这里只需要一个循环就可以得出结果啦~这个代码的时间复杂度是O(n)，但是我们的空间复杂度也达到了O(n)，我们发现很多数据都是只使用了一次就不再使用了，将这个数组改为3个变量循环交替使用可以加大使用效率。</p><pre><code class="c++">#include &lt;iostream&gt;#include &lt;vector&gt;using namespace std;long F(int n) {    long A, B, C;    A = 1;    B = 2;    if (n == 1) return A;    else if (n == 2) return B;    else {        for (int i = 3; i &lt;= n; i++) {            C = A + B;            A = B;            B = C;        }        return C;    }}int main() {    long result = F(100);    cout &lt;&lt; result;    return 0;}</code></pre><p>我们使用3个变量ABC交替使用，只要始终保持ABC的先后顺序就可以啦！这种方法还将空间复杂度降为了O(1)。当然这题我们发现刚好是求斐波那契数列的第101项，如果我们直接使用斐波那契数列求第n项公式可以在常数级的时间内求出结果，但那和动态规划没有关系啦~</p><p>总结一下：线性规划就是先用分治法的方法，从终点往前思考，用递归的方式定义解；然后我们发现其中有很多重复的子问题，这样我们又从起点开始，逐步记录已经求好的子问题的解，然后需要时再拿出来用，以此节约时间。</p>]]></content>
      
      
      
    </entry>
    
    
  
  
</search>
